"""
Stock analysis execution tool
"""

import sys
import os
import uuid
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv

# Import logging modules
from tradingagents.utils.logging_manager import get_logger, get_logger_manager
logger = get_logger('web')

# Add project root directory to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Ensure environment variables are loaded correctly
load_dotenv(project_root / ".env", override=True)

# Import unified logging system
from tradingagents.utils.logging_init import setup_web_logging
logger = setup_web_logging()

# Add configuration manager
try:
    from tradingagents.config.config_manager import token_tracker
    TOKEN_TRACKING_ENABLED = True
    logger.info("âœ… Token tracking feature enabled")
except ImportError:
    TOKEN_TRACKING_ENABLED = False
    logger.warning("âš ï¸ Token tracking feature not enabled")

def translate_analyst_labels(text):
    """Convert English analyst labels to Chinese"""
    if not text:
        return text

    # Analyst label translation mapping (Chinese to English)
    translations = {
        'çœ‹æ¶¨åˆ†æå¸ˆ:': 'Bull Analyst:',
        'çœ‹è·Œåˆ†æå¸ˆ:': 'Bear Analyst:',
        'æ¿€è¿›é£é™©åˆ†æå¸ˆ:': 'Risky Analyst:',
        'ä¿å®ˆé£é™©åˆ†æå¸ˆ:': 'Safe Analyst:',
        'ä¸­æ€§é£é™©åˆ†æå¸ˆ:': 'Neutral Analyst:',
        'ç ”ç©¶ç»ç†:': 'Research Manager:',
        'æŠ•èµ„ç»„åˆç»ç†:': 'Portfolio Manager:',
        'é£é™©ç®¡ç†å§”å‘˜ä¼š:': 'Risk Judge:',
        'äº¤æ˜“å‘˜:': 'Trader:'
    }

    # Replace all Chinese labels with English
    for chinese, english in translations.items():
        text = text.replace(chinese, english)

    return text

def extract_risk_assessment(state):
    """Extract risk assessment data from analysis state"""
    try:
        risk_debate_state = state.get('risk_debate_state', {})

        if not risk_debate_state:
            return None

        # Extract views from various risk analysts and convert to Chinese
        risky_analysis = translate_analyst_labels(risk_debate_state.get('risky_history', ''))
        safe_analysis = translate_analyst_labels(risk_debate_state.get('safe_history', ''))
        neutral_analysis = translate_analyst_labels(risk_debate_state.get('neutral_history', ''))
        judge_decision = translate_analyst_labels(risk_debate_state.get('judge_decision', ''))

        # Format risk assessment report
        risk_assessment = f"""
## âš ï¸ Risk Assessment Report

### ğŸ”´ Risky Analyst Perspective
{risky_analysis if risky_analysis else 'No risky analysis available'}

### ğŸŸ¡ Neutral Analyst Perspective
{neutral_analysis if neutral_analysis else 'No neutral analysis available'}

### ğŸŸ¢ Safe Analyst Perspective
{safe_analysis if safe_analysis else 'No safe analysis available'}

### ğŸ›ï¸ Risk Management Committee Final Decision
{judge_decision if judge_decision else 'No risk management decision available'}

---
*Risk assessment is based on multi-perspective analysis. Please make investment decisions based on your personal risk tolerance.*
        """.strip()

        return risk_assessment

    except Exception as e:
        logger.info(f"Error extracting risk assessment data: {e}")
        return None

def run_stock_analysis(stock_symbol, analysis_date, analysts, research_depth, llm_provider, llm_model, market_type="US Stock", progress_callback=None):
    """Execute stock analysis

    Args:
        stock_symbol: Stock symbol
        analysis_date: Analysis date
        analysts: List of analysts
        research_depth: Research depth
        llm_provider: LLM provider (dashscope/deepseek/google)
        llm_model: LLM model name
        progress_callback: Progress callback function for updating UI status
    """

    def update_progress(message, step=None, total_steps=None):
        """Update progress"""
        if progress_callback:
            progress_callback(message, step, total_steps)
        logger.info(f"[Progress] {message}")

    # Generate session ID for token tracking and log correlation
    session_id = f"analysis_{uuid.uuid4().hex[:8]}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    # 1. Data pre-fetching and validation phase
    update_progress("ğŸ” Validating stock code and pre-fetching data...", 1, 10)

    try:
        from tradingagents.utils.stock_validator import prepare_stock_data

        # Pre-fetch stock data (default 30 days historical data)
        preparation_result = prepare_stock_data(
            stock_code=stock_symbol,
            market_type=market_type,
            period_days=30,  # Can be adjusted based on research_depth
            analysis_date=analysis_date
        )

        if not preparation_result.is_valid:
            error_msg = f"âŒ Stock data validation failed: {preparation_result.error_message}"
            update_progress(error_msg)
            logger.error(f"[{session_id}] {error_msg}")

            return {
                'success': False,
                'error': preparation_result.error_message,
                'suggestion': preparation_result.suggestion,
                'stock_symbol': stock_symbol,
                'analysis_date': analysis_date,
                'session_id': session_id
            }

        # Data pre-fetching successful
        success_msg = f"âœ… Data preparation completed: {preparation_result.stock_name} ({preparation_result.market_type})"
        update_progress(success_msg)  # Use intelligent detection, no longer hardcode steps
        logger.info(f"[{session_id}] {success_msg}")
        logger.info(f"[{session_id}] Cache status: {preparation_result.cache_status}")

    except Exception as e:
        error_msg = f"âŒ Error occurred during data pre-fetching: {str(e)}"
        update_progress(error_msg)
        logger.error(f"[{session_id}] {error_msg}")

        return {
            'success': False,
            'error': error_msg,
            'suggestion': "Please check network connection or try again later",
            'stock_symbol': stock_symbol,
            'analysis_date': analysis_date,
            'session_id': session_id
        }

    # Record detailed logs for analysis start
    logger_manager = get_logger_manager()
    import time
    analysis_start_time = time.time()

    logger_manager.log_analysis_start(
        logger, stock_symbol, "comprehensive_analysis", session_id
    )

    logger.info(f"ğŸš€ [Analysis Start] Stock analysis initiated",
               extra={
                   'stock_symbol': stock_symbol,
                   'analysis_date': analysis_date,
                   'analysts': analysts,
                   'research_depth': research_depth,
                   'llm_provider': llm_provider,
                   'llm_model': llm_model,
                   'market_type': market_type,
                   'session_id': session_id,
                   'event_type': 'web_analysis_start'
               })

    update_progress("ğŸš€ Starting stock analysis...")

    # Estimate token usage (for cost estimation)
    if TOKEN_TRACKING_ENABLED:
        estimated_input = 2000 * len(analysts)  # Estimate 2000 input tokens per analyst
        estimated_output = 1000 * len(analysts)  # Estimate 1000 output tokens per analyst
        estimated_cost = token_tracker.estimate_cost(llm_provider, llm_model, estimated_input, estimated_output)

        update_progress(f"ğŸ’° Estimated analysis cost: Â¥{estimated_cost:.4f}")

    # Validate environment variables
    update_progress("Checking environment variable configuration...")
    dashscope_key = os.getenv("DASHSCOPE_API_KEY")
    finnhub_key = os.getenv("FINNHUB_API_KEY")

    logger.info(f"Environment variable check:")
    logger.info(f"  DASHSCOPE_API_KEY: {'Set' if dashscope_key else 'Not set'}")
    logger.info(f"  FINNHUB_API_KEY: {'Set' if finnhub_key else 'Not set'}")

    if not dashscope_key:
        raise ValueError("DASHSCOPE_API_KEY environment variable not set")
    if not finnhub_key:
        raise ValueError("FINNHUB_API_KEY environment variable not set")

    update_progress("Environment variable validation passed")

    try:
        # Import necessary modules
        from tradingagents.graph.trading_graph import TradingAgentsGraph
        from tradingagents.default_config import DEFAULT_CONFIG

        # Create configuration
        update_progress("Configuring analysis parameters...")
        config = DEFAULT_CONFIG.copy()
        config["llm_provider"] = llm_provider
        config["deep_think_llm"] = llm_model
        config["quick_think_llm"] = llm_model
        # Adjust configuration based on research depth
        if research_depth == 1:  # Level 1 - Quick analysis
            config["max_debate_rounds"] = 1
            config["max_risk_discuss_rounds"] = 1
            # Keep memory function enabled, as memory operations have minimal overhead but significantly improve analysis quality
            config["memory_enabled"] = True

            # Use online tools uniformly to avoid various issues with offline tools
            config["online_tools"] = True  # All markets use unified tools
            logger.info(f"ğŸ”§ [Quick Analysis] {market_type} using unified tools to ensure correct data sources and stability")
            if llm_provider == "dashscope":
                config["quick_think_llm"] = "qwen-turbo"  # Use fastest model
                config["deep_think_llm"] = "qwen-plus"
            elif llm_provider == "deepseek":
                config["quick_think_llm"] = "deepseek-chat"  # DeepSeekåªæœ‰ä¸€ä¸ªæ¨¡å‹
                config["deep_think_llm"] = "deepseek-chat"
        elif research_depth == 2:  # 2çº§ - åŸºç¡€åˆ†æ
            config["max_debate_rounds"] = 1
            config["max_risk_discuss_rounds"] = 1
            config["memory_enabled"] = True
            config["online_tools"] = True
            if llm_provider == "dashscope":
                config["quick_think_llm"] = "qwen-plus"
                config["deep_think_llm"] = "qwen-plus"
            elif llm_provider == "deepseek":
                config["quick_think_llm"] = "deepseek-chat"
                config["deep_think_llm"] = "deepseek-chat"
            elif llm_provider == "openai":
                config["quick_think_llm"] = llm_model
                config["deep_think_llm"] = llm_model
            elif llm_provider == "openai":
                config["quick_think_llm"] = llm_model
                config["deep_think_llm"] = llm_model
            elif llm_provider == "openai":
                config["quick_think_llm"] = llm_model
                config["deep_think_llm"] = llm_model
            elif llm_provider == "openai":
                config["quick_think_llm"] = llm_model
                config["deep_think_llm"] = llm_model
            elif llm_provider == "openai":
                config["quick_think_llm"] = llm_model
                config["deep_think_llm"] = llm_model
            elif llm_provider == "openai":
                config["quick_think_llm"] = llm_model
                config["deep_think_llm"] = llm_model
        elif research_depth == 3:  # 3çº§ - æ ‡å‡†åˆ†æ (é»˜è®¤)
            config["max_debate_rounds"] = 1
            config["max_risk_discuss_rounds"] = 2
            config["memory_enabled"] = True
            config["online_tools"] = True
            if llm_provider == "dashscope":
                config["quick_think_llm"] = "qwen-plus"
                config["deep_think_llm"] = "qwen-max"
            elif llm_provider == "deepseek":
                config["quick_think_llm"] = "deepseek-chat"
                config["deep_think_llm"] = "deepseek-chat"
        elif research_depth == 4:  # 4çº§ - æ·±åº¦åˆ†æ
            config["max_debate_rounds"] = 2
            config["max_risk_discuss_rounds"] = 2
            config["memory_enabled"] = True
            config["online_tools"] = True
            if llm_provider == "dashscope":
                config["quick_think_llm"] = "qwen-plus"
                config["deep_think_llm"] = "qwen-max"
            elif llm_provider == "deepseek":
                config["quick_think_llm"] = "deepseek-chat"
                config["deep_think_llm"] = "deepseek-chat"
        else:  # 5çº§ - å…¨é¢åˆ†æ
            config["max_debate_rounds"] = 3
            config["max_risk_discuss_rounds"] = 3
            config["memory_enabled"] = True
            config["online_tools"] = True
            if llm_provider == "dashscope":
                config["quick_think_llm"] = "qwen-max"
                config["deep_think_llm"] = "qwen-max"
            elif llm_provider == "deepseek":
                config["quick_think_llm"] = "deepseek-chat"
                config["deep_think_llm"] = "deepseek-chat"

        # Set different configurations based on LLM provider
        if llm_provider == "dashscope":
            config["backend_url"] = "https://dashscope.aliyuncs.com/api/v1"
        elif llm_provider == "deepseek":
            config["backend_url"] = "https://api.deepseek.com"
        elif llm_provider == "qianfan":
            # Qianfan (ERNIE) configuration
            config["backend_url"] = "https://aip.baidubce.com"
            # Set Qianfan models based on research depth
            if research_depth <= 2:  # Quick and basic analysis
                config["quick_think_llm"] = "ernie-3.5-8k"
                config["deep_think_llm"] = "ernie-3.5-8k"
            elif research_depth <= 4:  # Standard and deep analysis
                config["quick_think_llm"] = "ernie-3.5-8k"
                config["deep_think_llm"] = "ernie-4.0-turbo-8k"
            else:  # Comprehensive analysis
                config["quick_think_llm"] = "ernie-4.0-turbo-8k"
                config["deep_think_llm"] = "ernie-4.0-turbo-8k"
            
            logger.info(f"ğŸ¤– [Qianfan] Quick model: {config['quick_think_llm']}")
            logger.info(f"ğŸ¤– [Qianfan] Deep model: {config['deep_think_llm']}")
        elif llm_provider == "google":
            # Google AI doesn't need backend_url, use default OpenAI format
            config["backend_url"] = "https://api.openai.com/v1"
            
            # Optimize Google model selection based on research depth
            if research_depth == 1:  # Quick analysis - use fastest model
                config["quick_think_llm"] = "gemini-2.5-flash-lite-preview-06-17"  # 1.45s
                config["deep_think_llm"] = "gemini-2.0-flash"  # 1.87s
            elif research_depth == 2:  # Basic analysis - use fast model
                config["quick_think_llm"] = "gemini-2.0-flash"  # 1.87s
                config["deep_think_llm"] = "gemini-1.5-pro"  # 2.25s
            elif research_depth == 3:  # Standard analysis - balanced performance
                config["quick_think_llm"] = "gemini-1.5-pro"  # 2.25s
                config["deep_think_llm"] = "gemini-2.5-flash"  # 2.73s
            elif research_depth == 4:  # Deep analysis - use powerful model
                config["quick_think_llm"] = "gemini-2.5-flash"  # 2.73s
                config["deep_think_llm"] = "gemini-2.5-pro"  # 16.68s
            else:  # Comprehensive analysis - use strongest model
                config["quick_think_llm"] = "gemini-2.5-pro"  # 16.68s
                config["deep_think_llm"] = "gemini-2.5-pro"  # 16.68s
            
            logger.info(f"ğŸ¤– [Google AI] å¿«é€Ÿæ¨¡å‹: {config['quick_think_llm']}")
            logger.info(f"ğŸ¤– [Google AI] æ·±åº¦æ¨¡å‹: {config['deep_think_llm']}")
        elif llm_provider == "openai":
            # OpenAIå®˜æ–¹API
            config["backend_url"] = "https://api.openai.com/v1"
            logger.info(f"ğŸ¤– [OpenAI] ä½¿ç”¨æ¨¡å‹: {llm_model}")
            logger.info(f"ğŸ¤– [OpenAI] APIç«¯ç‚¹: https://api.openai.com/v1")
        elif llm_provider == "openrouter":
            # OpenRouterä½¿ç”¨OpenAIå…¼å®¹API
            config["backend_url"] = "https://openrouter.ai/api/v1"
            logger.info(f"ğŸŒ [OpenRouter] ä½¿ç”¨æ¨¡å‹: {llm_model}")
            logger.info(f"ğŸŒ [OpenRouter] APIç«¯ç‚¹: https://openrouter.ai/api/v1")
        elif llm_provider == "siliconflow":
            config["backend_url"] = "https://api.siliconflow.cn/v1"
            logger.info(f"ğŸŒ [SiliconFlow] ä½¿ç”¨æ¨¡å‹: {llm_model}")
            logger.info(f"ğŸŒ [SiliconFlow] APIç«¯ç‚¹: https://api.siliconflow.cn/v1")
        elif llm_provider == "custom_openai":
            # è‡ªå®šä¹‰OpenAIç«¯ç‚¹
            custom_base_url = st.session_state.get("custom_openai_base_url", "https://api.openai.com/v1")
            config["backend_url"] = custom_base_url
            config["custom_openai_base_url"] = custom_base_url
            logger.info(f"ğŸ”§ [è‡ªå®šä¹‰OpenAI] ä½¿ç”¨æ¨¡å‹: {llm_model}")
            logger.info(f"ğŸ”§ [è‡ªå®šä¹‰OpenAI] APIç«¯ç‚¹: {custom_base_url}")

        # ä¿®å¤è·¯å¾„é—®é¢˜ - ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡é…ç½®
        # æ•°æ®ç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        if not config.get("data_dir") or config["data_dir"] == "./data":
            env_data_dir = os.getenv("TRADINGAGENTS_DATA_DIR")
            if env_data_dir:
                # å¦‚æœç¯å¢ƒå˜é‡æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•è§£æ
                if not os.path.isabs(env_data_dir):
                    config["data_dir"] = str(project_root / env_data_dir)
                else:
                    config["data_dir"] = env_data_dir
            else:
                config["data_dir"] = str(project_root / "data")

        # ç»“æœç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        if not config.get("results_dir") or config["results_dir"] == "./results":
            env_results_dir = os.getenv("TRADINGAGENTS_RESULTS_DIR")
            if env_results_dir:
                # å¦‚æœç¯å¢ƒå˜é‡æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•è§£æ
                if not os.path.isabs(env_results_dir):
                    config["results_dir"] = str(project_root / env_results_dir)
                else:
                    config["results_dir"] = env_results_dir
            else:
                config["results_dir"] = str(project_root / "results")

        # ç¼“å­˜ç›®å½•ï¼šä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤è·¯å¾„
        if not config.get("data_cache_dir"):
            env_cache_dir = os.getenv("TRADINGAGENTS_CACHE_DIR")
            if env_cache_dir:
                # å¦‚æœç¯å¢ƒå˜é‡æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•è§£æ
                if not os.path.isabs(env_cache_dir):
                    config["data_cache_dir"] = str(project_root / env_cache_dir)
                else:
                    config["data_cache_dir"] = env_cache_dir
            else:
                config["data_cache_dir"] = str(project_root / "tradingagents" / "dataflows" / "data_cache")

        # Ensure directories exist
        update_progress("ğŸ“ Creating necessary directories...")
        os.makedirs(config["data_dir"], exist_ok=True)
        os.makedirs(config["results_dir"], exist_ok=True)
        os.makedirs(config["data_cache_dir"], exist_ok=True)

        logger.info(f"ğŸ“ Directory configuration:")
        logger.info(f"  - Data directory: {config['data_dir']}")
        logger.info(f"  - Results directory: {config['results_dir']}")
        logger.info(f"  - Cache directory: {config['data_cache_dir']}")
        logger.info(f"  - Environment variable TRADINGAGENTS_RESULTS_DIR: {os.getenv('TRADINGAGENTS_RESULTS_DIR', 'Not set')}")

        logger.info(f"Using configuration: {config}")
        logger.info(f"Analyst list: {analysts}")
        logger.info(f"Stock symbol: {stock_symbol}")
        logger.info(f"Analysis date: {analysis_date}")

        # Adjust stock symbol format based on market type
        logger.debug(f"ğŸ” [RUNNER DEBUG] ===== Stock Symbol Formatting =====")
        logger.debug(f"ğŸ” [RUNNER DEBUG] Original stock symbol: '{stock_symbol}'")
        logger.debug(f"ğŸ” [RUNNER DEBUG] Market type: '{market_type}'")

        if market_type == "Aè‚¡":
            # A-share codes don't need special handling, keep as is
            formatted_symbol = stock_symbol
            logger.debug(f"ğŸ” [RUNNER DEBUG] A-share code kept as is: '{formatted_symbol}'")
            update_progress(f"ğŸ‡¨ğŸ‡³ Preparing to analyze A-share: {formatted_symbol}")
        elif market_type == "æ¸¯è‚¡":
            # H-share codes converted to uppercase, ensure .HK suffix
            formatted_symbol = stock_symbol.upper()
            if not formatted_symbol.endswith('.HK'):
                # If it's pure digits, add .HK suffix
                if formatted_symbol.isdigit():
                    formatted_symbol = f"{formatted_symbol.zfill(4)}.HK"
            update_progress(f"ğŸ‡­ğŸ‡° Preparing to analyze H-share: {formatted_symbol}")
        else:
            # US stock codes converted to uppercase
            formatted_symbol = stock_symbol.upper()
            logger.debug(f"ğŸ” [RUNNER DEBUG] US stock code converted to uppercase: '{stock_symbol}' -> '{formatted_symbol}'")
            update_progress(f"ğŸ‡ºğŸ‡¸ Preparing to analyze US stock: {formatted_symbol}")

        logger.debug(f"ğŸ” [RUNNER DEBUG] Final stock symbol passed to analysis engine: '{formatted_symbol}'")

        # Initialize trading graph
        update_progress("ğŸ”§ Initializing analysis engine...")
        graph = TradingAgentsGraph(analysts, config=config, debug=False)

        # Execute analysis
        update_progress(f"ğŸ“Š Starting analysis of {formatted_symbol} stock, this may take a few minutes...")
        logger.debug(f"ğŸ” [RUNNER DEBUG] ===== Calling graph.propagate =====")
        logger.debug(f"ğŸ” [RUNNER DEBUG] Parameters passed to graph.propagate:")
        logger.debug(f"ğŸ” [RUNNER DEBUG]   symbol: '{formatted_symbol}'")
        logger.debug(f"ğŸ” [RUNNER DEBUG]   date: '{analysis_date}'")

        state, decision = graph.propagate(formatted_symbol, analysis_date)

        # Debug information
        logger.debug(f"ğŸ” [DEBUG] Analysis completed, decision type: {type(decision)}")
        logger.debug(f"ğŸ” [DEBUG] decision content: {decision}")

        # Format results
        update_progress("ğŸ“‹ Analysis completed, organizing results...")

        # Extract risk assessment data
        risk_assessment = extract_risk_assessment(state)

        # Add risk assessment to state
        if risk_assessment:
            state['risk_assessment'] = risk_assessment

        # Record token usage (actual usage, using estimates here)
        if TOKEN_TRACKING_ENABLED:
            # In actual application, these values should be obtained from LLM responses
            # Here using estimates based on number of analysts and research depth
            actual_input_tokens = len(analysts) * (1500 if research_depth == "å¿«é€Ÿ" else 2500 if research_depth == "æ ‡å‡†" else 4000)
            actual_output_tokens = len(analysts) * (800 if research_depth == "å¿«é€Ÿ" else 1200 if research_depth == "æ ‡å‡†" else 2000)

            usage_record = token_tracker.track_usage(
                provider=llm_provider,
                model_name=llm_model,
                input_tokens=actual_input_tokens,
                output_tokens=actual_output_tokens,
                session_id=session_id,
                analysis_type=f"{market_type}_analysis"
            )

            if usage_record:
                update_progress(f"ğŸ’° Recorded usage cost: Â¥{usage_record.cost:.4f}")

        results = {
            'stock_symbol': stock_symbol,
            'analysis_date': analysis_date,
            'analysts': analysts,
            'research_depth': research_depth,
            'llm_provider': llm_provider,
            'llm_model': llm_model,
            'state': state,
            'decision': decision,
            'success': True,
            'error': None,
            'session_id': session_id if TOKEN_TRACKING_ENABLED else None
        }

        # Record detailed log of analysis completion
        analysis_duration = time.time() - analysis_start_time

        # Calculate total cost (if token tracking enabled)
        total_cost = 0.0
        if TOKEN_TRACKING_ENABLED:
            try:
                total_cost = token_tracker.get_session_cost(session_id)
            except:
                pass

        logger_manager.log_analysis_complete(
            logger, stock_symbol, "comprehensive_analysis", session_id,
            analysis_duration, total_cost
        )

        logger.info(f"âœ… [Analysis Complete] Stock analysis successfully completed",
                   extra={
                       'stock_symbol': stock_symbol,
                       'session_id': session_id,
                       'duration': analysis_duration,
                       'total_cost': total_cost,
                       'analysts_used': analysts,
                       'success': True,
                       'event_type': 'web_analysis_complete'
                   })

        # Save analysis report to local and MongoDB
        try:
            update_progress("ğŸ’¾ Saving analysis report...")
            from .report_exporter import save_analysis_report, save_modular_reports_to_results_dir
            
            # 1. Save modular reports to local directory
            logger.info(f"ğŸ“ [Local Save] Starting to save modular reports to local directory")
            local_files = save_modular_reports_to_results_dir(results, stock_symbol)
            if local_files:
                logger.info(f"âœ… [Local Save] Saved {len(local_files)} local report files")
                for module, path in local_files.items():
                    logger.info(f"  - {module}: {path}")
            else:
                logger.warning(f"âš ï¸ [Local Save] Local report file save failed")
            
            # 2. Save analysis report to MongoDB
            logger.info(f"ğŸ—„ï¸ [MongoDB Save] Starting to save analysis report to MongoDB")
            save_success = save_analysis_report(
                stock_symbol=stock_symbol,
                analysis_results=results
            )
            
            if save_success:
                logger.info(f"âœ… [MongoDB Save] Analysis report successfully saved to MongoDB")
                update_progress("âœ… Analysis report saved to database and local files")
            else:
                logger.warning(f"âš ï¸ [MongoDB Save] MongoDB report save failed")
                if local_files:
                    update_progress("âœ… Local report saved, but database save failed")
                else:
                    update_progress("âš ï¸ Report save failed, but analysis completed")
                
        except Exception as save_error:
            logger.error(f"âŒ [Report Save] Error occurred while saving analysis report: {str(save_error)}")
            update_progress("âš ï¸ Report save error, but analysis completed")

        update_progress("âœ… Analysis successfully completed!")
        return results

    except Exception as e:
        # è®°å½•åˆ†æå¤±è´¥çš„è¯¦ç»†æ—¥å¿—
        analysis_duration = time.time() - analysis_start_time

        logger_manager.log_module_error(
            logger, "comprehensive_analysis", stock_symbol, session_id,
            analysis_duration, str(e)
        )

        logger.error(f"âŒ [åˆ†æå¤±è´¥] è‚¡ç¥¨åˆ†ææ‰§è¡Œå¤±è´¥",
                    extra={
                        'stock_symbol': stock_symbol,
                        'session_id': session_id,
                        'duration': analysis_duration,
                        'error': str(e),
                        'error_type': type(e).__name__,
                        'analysts_used': analysts,
                        'success': False,
                        'event_type': 'web_analysis_error'
                    }, exc_info=True)

        # å¦‚æœçœŸå®åˆ†æå¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯è€Œä¸æ˜¯è¯¯å¯¼æ€§æ¼”ç¤ºæ•°æ®
        return {
            'stock_symbol': stock_symbol,
            'analysis_date': analysis_date,
            'analysts': analysts,
            'research_depth': research_depth,
            'llm_provider': llm_provider,
            'llm_model': llm_model,
            'state': {},  # ç©ºçŠ¶æ€ï¼Œå°†æ˜¾ç¤ºå ä½ç¬¦
            'decision': {},  # ç©ºå†³ç­–
            'success': False,
            'error': str(e),
            'is_demo': False,
            'error_reason': f"åˆ†æå¤±è´¥: {str(e)}"
        }

def format_analysis_results(results):
    """æ ¼å¼åŒ–åˆ†æç»“æœç”¨äºæ˜¾ç¤º"""
    
    if not results['success']:
        return {
            'error': results['error'],
            'success': False
        }
    
    state = results['state']
    decision = results['decision']

    # æå–å…³é”®ä¿¡æ¯
    # decision å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆå¦‚ "BUY", "SELL", "HOLD"ï¼‰æˆ–å­—å…¸
    if isinstance(decision, str):
        # Convert English investment advice to Chinese
        action_translation = {
            'BUY': 'ä¹°å…¥',
            'SELL': 'å–å‡º',
            'HOLD': 'æŒæœ‰',
            'buy': 'ä¹°å…¥',
            'sell': 'å–å‡º',
            'hold': 'æŒæœ‰'
        }
        action = action_translation.get(decision.strip(), decision.strip())

        formatted_decision = {
            'action': action,
            'confidence': 0.7,  # Default confidence
            'risk_score': 0.3,  # Default risk score
            'target_price': None,  # String format has no target price
            'reasoning': f'Based on AI analysis, recommend {decision.strip().upper()}'
        }
    elif isinstance(decision, dict):
        # Handle target price - ensure correct numerical extraction
        target_price = decision.get('target_price')
        if target_price is not None and target_price != 'N/A':
            try:
                # Try to convert to float
                if isinstance(target_price, str):
                    # Remove currency symbols and spaces
                    clean_price = target_price.replace('$', '').replace('Â¥', '').replace('ï¿¥', '').strip()
                    target_price = float(clean_price) if clean_price and clean_price != 'None' else None
                elif isinstance(target_price, (int, float)):
                    target_price = float(target_price)
                else:
                    target_price = None
            except (ValueError, TypeError):
                target_price = None
        else:
            target_price = None

        # Convert English investment advice to Chinese
        action_translation = {
            'BUY': 'ä¹°å…¥',
            'SELL': 'å–å‡º',
            'HOLD': 'æŒæœ‰',
            'buy': 'ä¹°å…¥',
            'sell': 'å–å‡º',
            'hold': 'æŒæœ‰'
        }
        action = decision.get('action', 'æŒæœ‰')
        chinese_action = action_translation.get(action, action)

        formatted_decision = {
            'action': chinese_action,
            'confidence': decision.get('confidence', 0.5),
            'risk_score': decision.get('risk_score', 0.3),
            'target_price': target_price,
            'reasoning': decision.get('reasoning', 'No analysis reasoning available')
        }
    else:
        # Handle other types
        formatted_decision = {
            'action': 'æŒæœ‰',
            'confidence': 0.5,
            'risk_score': 0.3,
            'target_price': None,
            'reasoning': f'Analysis result: {str(decision)}'
        }
    
    # æ ¼å¼åŒ–çŠ¶æ€ä¿¡æ¯
    formatted_state = {}
    
    # å¤„ç†å„ä¸ªåˆ†ææ¨¡å—çš„ç»“æœ - åŒ…å«å®Œæ•´çš„æ™ºèƒ½ä½“å›¢é˜Ÿåˆ†æ
    analysis_keys = [
        'market_report',
        'fundamentals_report',
        'sentiment_report',
        'news_report',
        'risk_assessment',
        'investment_plan',
        # æ·»åŠ ç¼ºå¤±çš„å›¢é˜Ÿå†³ç­–æ•°æ®ï¼Œç¡®ä¿ä¸CLIç«¯ä¸€è‡´
        'investment_debate_state',  # ç ”ç©¶å›¢é˜Ÿè¾©è®ºï¼ˆå¤šå¤´/ç©ºå¤´ç ”ç©¶å‘˜ï¼‰
        'trader_investment_plan',   # äº¤æ˜“å›¢é˜Ÿè®¡åˆ’
        'risk_debate_state',        # é£é™©ç®¡ç†å›¢é˜Ÿå†³ç­–
        'final_trade_decision'      # æœ€ç»ˆäº¤æ˜“å†³ç­–
    ]
    
    for key in analysis_keys:
        if key in state:
            # å¯¹æ–‡æœ¬å†…å®¹è¿›è¡Œä¸­æ–‡åŒ–å¤„ç†
            content = state[key]
            if isinstance(content, str):
                content = translate_analyst_labels(content)
            formatted_state[key] = content
        elif key == 'risk_assessment':
            # ç‰¹æ®Šå¤„ç†ï¼šä» risk_debate_state ç”Ÿæˆ risk_assessment
            risk_assessment = extract_risk_assessment(state)
            if risk_assessment:
                formatted_state[key] = risk_assessment
    
    return {
        'stock_symbol': results['stock_symbol'],
        'decision': formatted_decision,
        'state': formatted_state,
        'success': True,
        # å°†é…ç½®ä¿¡æ¯æ”¾åœ¨é¡¶å±‚ï¼Œä¾›å‰ç«¯ç›´æ¥è®¿é—®
        'analysis_date': results['analysis_date'],
        'analysts': results['analysts'],
        'research_depth': results['research_depth'],
        'llm_provider': results.get('llm_provider', 'dashscope'),
        'llm_model': results['llm_model'],
        'metadata': {
            'analysis_date': results['analysis_date'],
            'analysts': results['analysts'],
            'research_depth': results['research_depth'],
            'llm_provider': results.get('llm_provider', 'dashscope'),
            'llm_model': results['llm_model']
        }
    }

def validate_analysis_params(stock_symbol, analysis_date, analysts, research_depth, market_type="US Stock"):
    """Validate analysis parameters"""

    errors = []

    # Validate stock symbol
    if not stock_symbol or len(stock_symbol.strip()) == 0:
        errors.append("Stock symbol cannot be empty")
    elif len(stock_symbol.strip()) > 10:
        errors.append("Stock symbol length cannot exceed 10 characters")
    else:
        # Validate code format based on market type
        symbol = stock_symbol.strip()
        if market_type == "Aè‚¡":
            # A-share: 6 digits
            import re
            if not re.match(r'^\d{6}$', symbol):
                errors.append("A-share code format error, should be 6 digits (e.g.: 000001)")
        elif market_type == "æ¸¯è‚¡":
            # H-share: 4-5 digits.HK or pure 4-5 digits
            import re
            symbol_upper = symbol.upper()
            # Check if it's XXXX.HK or XXXXX.HK format
            hk_format = re.match(r'^\d{4,5}\.HK$', symbol_upper)
            # Check if it's pure 4-5 digits format
            digit_format = re.match(r'^\d{4,5}$', symbol)

            if not (hk_format or digit_format):
                errors.append("H-share code format error, should be 4 digits.HK (e.g.: 0700.HK) or 4 digits (e.g.: 0700)")
        elif market_type == "US Stock":
            # US stock: 1-5 letters
            import re
            if not re.match(r'^[A-Z]{1,5}$', symbol.upper()):
                errors.append("US stock code format error, should be 1-5 letters (e.g.: AAPL)")
    
    # Validate analyst list
    if not analysts or len(analysts) == 0:
        errors.append("Must select at least one analyst")
    
    valid_analysts = ['market', 'social', 'news', 'fundamentals']
    invalid_analysts = [a for a in analysts if a not in valid_analysts]
    if invalid_analysts:
        errors.append(f"Invalid analyst types: {', '.join(invalid_analysts)}")
    
    # Validate research depth
    if not isinstance(research_depth, int) or research_depth < 1 or research_depth > 5:
        errors.append("Research depth must be an integer between 1-5")
    
    # Validate analysis date
    try:
        from datetime import datetime
        datetime.strptime(analysis_date, '%Y-%m-%d')
    except ValueError:
        errors.append("Invalid analysis date format, should be YYYY-MM-DD format")
    
    return len(errors) == 0, errors

def get_supported_stocks():
    """Get list of supported stocks"""
    
    # Common US stock symbols
    popular_stocks = [
        {'symbol': 'AAPL', 'name': 'Apple Inc.', 'sector': 'Technology'},
        {'symbol': 'MSFT', 'name': 'Microsoft', 'sector': 'Technology'},
        {'symbol': 'GOOGL', 'name': 'Google', 'sector': 'Technology'},
        {'symbol': 'AMZN', 'name': 'Amazon', 'sector': 'Consumer'},
        {'symbol': 'TSLA', 'name': 'Tesla', 'sector': 'Automotive'},
        {'symbol': 'NVDA', 'name': 'NVIDIA', 'sector': 'Technology'},
        {'symbol': 'META', 'name': 'Meta', 'sector': 'Technology'},
        {'symbol': 'NFLX', 'name': 'Netflix', 'sector': 'Media'},
        {'symbol': 'AMD', 'name': 'AMD', 'sector': 'Technology'},
        {'symbol': 'INTC', 'name': 'Intel', 'sector': 'Technology'},
        {'symbol': 'SPY', 'name': 'S&P 500 ETF', 'sector': 'ETF'},
        {'symbol': 'QQQ', 'name': 'Nasdaq 100 ETF', 'sector': 'ETF'},
    ]
    
    return popular_stocks

def generate_demo_results_deprecated(stock_symbol, analysis_date, analysts, research_depth, llm_provider, llm_model, error_msg, market_type="US Stock"):
    """
    Deprecated: Generate demo analysis results

    Note: This function is deprecated because demo data can mislead users.
    We now use placeholders instead of demo data.
    """

    import random

    # Set currency symbol and price range based on market type
    if market_type == "HK Stock":
        currency_symbol = "HK$"
        price_range = (50, 500)  # HK stock price range
        market_name = "HK Stock"
    elif market_type == "A Stock":
        currency_symbol = "Â¥"
        price_range = (5, 100)   # A stock price range
        market_name = "A Stock"
    else:  # US Stock
        currency_symbol = "$"
        price_range = (50, 300)  # US stock price range
        market_name = "US Stock"

    # Generate simulated decision
    actions = ['BUY', 'HOLD', 'SELL']
    action = random.choice(actions)

    demo_decision = {
        'action': action,
        'confidence': round(random.uniform(0.6, 0.9), 2),
        'risk_score': round(random.uniform(0.2, 0.7), 2),
        'target_price': round(random.uniform(*price_range), 2),
        'reasoning': f"""
Based on comprehensive analysis of {market_name} {stock_symbol}, our AI analysis team concludes:

**Investment Recommendation**: {action}
**Target Price**: {currency_symbol}{round(random.uniform(*price_range), 2)}

**Key Analysis Points**:
1. **Technical Analysis**: Current price trend shows {'upward' if action == 'BUY' else 'downward' if action == 'SELL' else 'sideways'} signals
2. **Fundamental Assessment**: Company financial condition is {'good' if action == 'BUY' else 'average' if action == 'HOLD' else 'needs attention'}
3. **Market Sentiment**: Investor sentiment is {'optimistic' if action == 'BUY' else 'neutral' if action == 'HOLD' else 'cautious'}
4. **Risk Assessment**: Current risk level is {'moderate' if action == 'HOLD' else 'low' if action == 'BUY' else 'high'}

**Note**: This is demo data, actual analysis requires proper API key configuration.
        """
    }

    # Generate simulated state data
    demo_state = {}

    if 'market' in analysts:
        current_price = round(random.uniform(*price_range), 2)
        high_price = round(current_price * random.uniform(1.2, 1.8), 2)
        low_price = round(current_price * random.uniform(0.5, 0.8), 2)

        demo_state['market_report'] = f"""
## ğŸ“ˆ {market_name}{stock_symbol} æŠ€æœ¯é¢åˆ†ææŠ¥å‘Š

### ä»·æ ¼è¶‹åŠ¿åˆ†æ
- **å½“å‰ä»·æ ¼**: {currency_symbol}{current_price}
- **æ—¥å†…å˜åŒ–**: {random.choice(['+', '-'])}{round(random.uniform(0.5, 5), 2)}%
- **52å‘¨é«˜ç‚¹**: {currency_symbol}{high_price}
- **52å‘¨ä½ç‚¹**: {currency_symbol}{low_price}

### æŠ€æœ¯æŒ‡æ ‡
- **RSI (14æ—¥)**: {round(random.uniform(30, 70), 1)}
- **MACD**: {'çœ‹æ¶¨' if action == 'BUY' else 'çœ‹è·Œ' if action == 'SELL' else 'ä¸­æ€§'}
- **ç§»åŠ¨å¹³å‡çº¿**: ä»·æ ¼{'é«˜äº' if action == 'BUY' else 'ä½äº' if action == 'SELL' else 'æ¥è¿‘'}20æ—¥å‡çº¿

### æ”¯æ’‘é˜»åŠ›ä½
- **æ”¯æ’‘ä½**: ${round(random.uniform(80, 120), 2)}
- **é˜»åŠ›ä½**: ${round(random.uniform(250, 350), 2)}

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…åˆ†æéœ€è¦é…ç½®APIå¯†é’¥*
        """

    if 'fundamentals' in analysts:
        demo_state['fundamentals_report'] = f"""
## ğŸ’° {stock_symbol} åŸºæœ¬é¢åˆ†ææŠ¥å‘Š

### è´¢åŠ¡æŒ‡æ ‡
- **å¸‚ç›ˆç‡ (P/E)**: {round(random.uniform(15, 35), 1)}
- **å¸‚å‡€ç‡ (P/B)**: {round(random.uniform(1, 5), 1)}
- **å‡€èµ„äº§æ”¶ç›Šç‡ (ROE)**: {round(random.uniform(10, 25), 1)}%
- **æ¯›åˆ©ç‡**: {round(random.uniform(20, 60), 1)}%

### ç›ˆåˆ©èƒ½åŠ›
- **è¥æ”¶å¢é•¿**: {random.choice(['+', '-'])}{round(random.uniform(5, 20), 1)}%
- **å‡€åˆ©æ¶¦å¢é•¿**: {random.choice(['+', '-'])}{round(random.uniform(10, 30), 1)}%
- **æ¯è‚¡æ”¶ç›Š**: ${round(random.uniform(2, 15), 2)}

### è´¢åŠ¡å¥åº·åº¦
- **è´Ÿå€ºç‡**: {round(random.uniform(20, 60), 1)}%
- **æµåŠ¨æ¯”ç‡**: {round(random.uniform(1, 3), 1)}
- **ç°é‡‘æµ**: {'æ­£å‘' if action != 'SELL' else 'éœ€å…³æ³¨'}

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…åˆ†æéœ€è¦é…ç½®APIå¯†é’¥*
        """

    if 'social' in analysts:
        demo_state['sentiment_report'] = f"""
## ğŸ’­ {stock_symbol} å¸‚åœºæƒ…ç»ªåˆ†ææŠ¥å‘Š

### ç¤¾äº¤åª’ä½“æƒ…ç»ª
- **æ•´ä½“æƒ…ç»ª**: {'ç§¯æ' if action == 'BUY' else 'æ¶ˆæ' if action == 'SELL' else 'ä¸­æ€§'}
- **æƒ…ç»ªå¼ºåº¦**: {round(random.uniform(0.5, 0.9), 2)}
- **è®¨è®ºçƒ­åº¦**: {'é«˜' if random.random() > 0.5 else 'ä¸­ç­‰'}

### æŠ•èµ„è€…æƒ…ç»ªæŒ‡æ ‡
- **ææ…Œè´ªå©ªæŒ‡æ•°**: {round(random.uniform(20, 80), 0)}
- **çœ‹æ¶¨çœ‹è·Œæ¯”**: {round(random.uniform(0.8, 1.5), 2)}
- **æœŸæƒPut/Callæ¯”**: {round(random.uniform(0.5, 1.2), 2)}

### æœºæ„æŠ•èµ„è€…åŠ¨å‘
- **æœºæ„æŒä»“å˜åŒ–**: {random.choice(['å¢æŒ', 'å‡æŒ', 'ç»´æŒ'])}
- **åˆ†æå¸ˆè¯„çº§**: {'ä¹°å…¥' if action == 'BUY' else 'å–å‡º' if action == 'SELL' else 'æŒæœ‰'}

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…åˆ†æéœ€è¦é…ç½®APIå¯†é’¥*
        """

    if 'news' in analysts:
        demo_state['news_report'] = f"""
## ğŸ“° {stock_symbol} æ–°é—»äº‹ä»¶åˆ†ææŠ¥å‘Š

### è¿‘æœŸé‡è¦æ–°é—»
1. **è´¢æŠ¥å‘å¸ƒ**: å…¬å¸å‘å¸ƒ{'è¶…é¢„æœŸ' if action == 'BUY' else 'ä½äºé¢„æœŸ' if action == 'SELL' else 'ç¬¦åˆé¢„æœŸ'}çš„å­£åº¦è´¢æŠ¥
2. **è¡Œä¸šåŠ¨æ€**: æ‰€åœ¨è¡Œä¸šé¢ä¸´{'åˆ©å¥½' if action == 'BUY' else 'æŒ‘æˆ˜' if action == 'SELL' else 'ç¨³å®š'}æ”¿ç­–ç¯å¢ƒ
3. **å…¬å¸å…¬å‘Š**: ç®¡ç†å±‚{'ä¹è§‚' if action == 'BUY' else 'è°¨æ…' if action == 'SELL' else 'ç¨³å¥'}å±•æœ›æœªæ¥

### æ–°é—»æƒ…ç»ªåˆ†æ
- **æ­£é¢æ–°é—»å æ¯”**: {round(random.uniform(40, 80), 0)}%
- **è´Ÿé¢æ–°é—»å æ¯”**: {round(random.uniform(10, 40), 0)}%
- **ä¸­æ€§æ–°é—»å æ¯”**: {round(random.uniform(20, 50), 0)}%

### å¸‚åœºå½±å“è¯„ä¼°
- **çŸ­æœŸå½±å“**: {'æ­£é¢' if action == 'BUY' else 'è´Ÿé¢' if action == 'SELL' else 'ä¸­æ€§'}
- **é•¿æœŸå½±å“**: {'ç§¯æ' if action != 'SELL' else 'éœ€è§‚å¯Ÿ'}

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…åˆ†æéœ€è¦é…ç½®APIå¯†é’¥*
        """

    # æ·»åŠ é£é™©è¯„ä¼°å’ŒæŠ•èµ„å»ºè®®
    demo_state['risk_assessment'] = f"""
## âš ï¸ {stock_symbol} é£é™©è¯„ä¼°æŠ¥å‘Š

### ä¸»è¦é£é™©å› ç´ 
1. **å¸‚åœºé£é™©**: {'ä½' if action == 'BUY' else 'é«˜' if action == 'SELL' else 'ä¸­ç­‰'}
2. **è¡Œä¸šé£é™©**: {'å¯æ§' if action != 'SELL' else 'éœ€å…³æ³¨'}
3. **å…¬å¸ç‰¹å®šé£é™©**: {'è¾ƒä½' if action == 'BUY' else 'ä¸­ç­‰'}

### é£é™©ç­‰çº§è¯„ä¼°
- **æ€»ä½“é£é™©ç­‰çº§**: {'ä½é£é™©' if action == 'BUY' else 'é«˜é£é™©' if action == 'SELL' else 'ä¸­ç­‰é£é™©'}
- **å»ºè®®ä»“ä½**: {random.choice(['è½»ä»“', 'æ ‡å‡†ä»“ä½', 'é‡ä»“']) if action != 'SELL' else 'å»ºè®®å‡ä»“'}

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…åˆ†æéœ€è¦é…ç½®APIå¯†é’¥*
    """

    demo_state['investment_plan'] = f"""
## ğŸ“‹ {stock_symbol} æŠ•èµ„å»ºè®®

### å…·ä½“æ“ä½œå»ºè®®
- **æ“ä½œæ–¹å‘**: {action}
- **å»ºè®®ä»·ä½**: ${round(random.uniform(90, 310), 2)}
- **æ­¢æŸä½**: ${round(random.uniform(80, 200), 2)}
- **ç›®æ ‡ä»·ä½**: ${round(random.uniform(150, 400), 2)}

### æŠ•èµ„ç­–ç•¥
- **æŠ•èµ„æœŸé™**: {'çŸ­æœŸ' if research_depth <= 2 else 'ä¸­é•¿æœŸ'}
- **ä»“ä½ç®¡ç†**: {'åˆ†æ‰¹å»ºä»“' if action == 'BUY' else 'åˆ†æ‰¹å‡ä»“' if action == 'SELL' else 'ç»´æŒç°çŠ¶'}

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…åˆ†æéœ€è¦é…ç½®APIå¯†é’¥*
    """

    # æ·»åŠ å›¢é˜Ÿå†³ç­–æ¼”ç¤ºæ•°æ®ï¼Œç¡®ä¿ä¸CLIç«¯ä¸€è‡´
    demo_state['investment_debate_state'] = {
        'bull_history': f"""
## ğŸ“ˆ å¤šå¤´ç ”ç©¶å‘˜åˆ†æ

ä½œä¸ºå¤šå¤´ç ”ç©¶å‘˜ï¼Œæˆ‘å¯¹{stock_symbol}æŒä¹è§‚æ€åº¦ï¼š

### ğŸš€ æŠ•èµ„äº®ç‚¹
1. **æŠ€æœ¯é¢çªç ´**: è‚¡ä»·çªç ´å…³é”®é˜»åŠ›ä½ï¼ŒæŠ€æœ¯å½¢æ€è‰¯å¥½
2. **åŸºæœ¬é¢æ”¯æ’‘**: å…¬å¸ä¸šç»©ç¨³å¥å¢é•¿ï¼Œè´¢åŠ¡çŠ¶å†µå¥åº·
3. **å¸‚åœºæœºä¼š**: å½“å‰ä¼°å€¼åˆç†ï¼Œå…·å¤‡ä¸Šæ¶¨ç©ºé—´

### ğŸ“Š æ•°æ®æ”¯æŒ
- è¿‘æœŸæˆäº¤é‡æ”¾å¤§ï¼Œèµ„é‡‘æµå…¥æ˜æ˜¾
- è¡Œä¸šæ™¯æ°”åº¦æå‡ï¼Œæ”¿ç­–ç¯å¢ƒæœ‰åˆ©
- æœºæ„æŠ•èµ„è€…å¢æŒï¼Œå¸‚åœºä¿¡å¿ƒå¢å¼º

**å»ºè®®**: ç§¯æä¹°å…¥ï¼Œç›®æ ‡ä»·ä½ä¸Šè°ƒ15-20%

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®*
        """.strip(),

        'bear_history': f"""
## ğŸ“‰ ç©ºå¤´ç ”ç©¶å‘˜åˆ†æ

ä½œä¸ºç©ºå¤´ç ”ç©¶å‘˜ï¼Œæˆ‘å¯¹{stock_symbol}æŒè°¨æ…æ€åº¦ï¼š

### âš ï¸ é£é™©å› ç´ 
1. **ä¼°å€¼åé«˜**: å½“å‰å¸‚ç›ˆç‡è¶…è¿‡è¡Œä¸šå¹³å‡æ°´å¹³
2. **æŠ€æœ¯é£é™©**: çŸ­æœŸæ¶¨å¹…è¿‡å¤§ï¼Œå­˜åœ¨å›è°ƒå‹åŠ›
3. **å®è§‚ç¯å¢ƒ**: å¸‚åœºæ•´ä½“æ³¢åŠ¨åŠ å¤§ï¼Œä¸ç¡®å®šæ€§å¢åŠ 

### ğŸ“‰ æ‹…å¿§ç‚¹
- æˆäº¤é‡è™½ç„¶æ”¾å¤§ï¼Œä½†å¯èƒ½æ˜¯è·åˆ©ç›˜å‡ºè´§
- è¡Œä¸šç«äº‰åŠ å‰§ï¼Œå…¬å¸å¸‚åœºä»½é¢é¢ä¸´æŒ‘æˆ˜
- æ”¿ç­–å˜åŒ–å¯èƒ½å¯¹è¡Œä¸šäº§ç”Ÿè´Ÿé¢å½±å“

**å»ºè®®**: è°¨æ…è§‚æœ›ï¼Œç­‰å¾…æ›´å¥½çš„å…¥åœºæ—¶æœº

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®*
        """.strip(),

        'judge_decision': f"""
## ğŸ¯ ç ”ç©¶ç»ç†ç»¼åˆå†³ç­–

ç»è¿‡aedaå’Œç©ºå¤´ç ”ç©¶å‘˜çš„å……åˆ†è¾©è®ºï¼Œæˆ‘çš„ç»¼åˆåˆ¤æ–­å¦‚ä¸‹ï¼š

### ğŸ“Š ç»¼åˆè¯„ä¼°
- **å¤šå¤´è§‚ç‚¹**: æŠ€æœ¯é¢å’ŒåŸºæœ¬é¢éƒ½æ˜¾ç¤ºç§¯æä¿¡å·
- **ç©ºå¤´è§‚ç‚¹**: ä¼°å€¼å’ŒçŸ­æœŸé£é™©éœ€è¦å…³æ³¨
- **å¹³è¡¡è€ƒè™‘**: æœºä¼šä¸é£é™©å¹¶å­˜ï¼Œéœ€è¦ç­–ç•¥æ€§æ“ä½œ

### ğŸ¯ æœ€ç»ˆå»ºè®®
åŸºäºå½“å‰å¸‚åœºç¯å¢ƒå’Œ{stock_symbol}çš„å…·ä½“æƒ…å†µï¼Œå»ºè®®é‡‡å–**{action}**ç­–ç•¥ï¼š

1. **æ“ä½œå»ºè®®**: {action}
2. **ä»“ä½æ§åˆ¶**: {'åˆ†æ‰¹å»ºä»“' if action == 'ä¹°å…¥' else 'åˆ†æ‰¹å‡ä»“' if action == 'å–å‡º' else 'ç»´æŒç°çŠ¶'}
3. **é£é™©ç®¡ç†**: è®¾ç½®æ­¢æŸä½ï¼Œæ§åˆ¶å•åªè‚¡ç¥¨ä»“ä½ä¸è¶…è¿‡10%

**å†³ç­–ä¾æ®**: ç»¼åˆæŠ€æœ¯é¢ã€åŸºæœ¬é¢å’Œå¸‚åœºæƒ…ç»ªåˆ†æ

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®*
        """.strip()
    }

    demo_state['trader_investment_plan'] = f"""
## ğŸ’¼ äº¤æ˜“å›¢é˜Ÿæ‰§è¡Œè®¡åˆ’

åŸºäºç ”ç©¶å›¢é˜Ÿçš„åˆ†æç»“æœï¼Œåˆ¶å®šå¦‚ä¸‹äº¤æ˜“æ‰§è¡Œè®¡åˆ’ï¼š

### ğŸ¯ äº¤æ˜“ç­–ç•¥
- **äº¤æ˜“æ–¹å‘**: {action}
- **ç›®æ ‡ä»·ä½**: {currency_symbol}{round(random.uniform(*price_range) * 1.1, 2)}
- **æ­¢æŸä»·ä½**: {currency_symbol}{round(random.uniform(*price_range) * 0.9, 2)}

### ğŸ“Š ä»“ä½ç®¡ç†
- **å»ºè®®ä»“ä½**: {'30-50%' if action == 'ä¹°å…¥' else 'å‡ä»“è‡³20%' if action == 'å–å‡º' else 'ç»´æŒç°æœ‰ä»“ä½'}
- **åˆ†æ‰¹æ“ä½œ**: {'åˆ†3æ¬¡å»ºä»“' if action == 'ä¹°å…¥' else 'åˆ†2æ¬¡å‡ä»“' if action == 'å–å‡º' else 'æš‚ä¸æ“ä½œ'}
- **æ—¶é—´å®‰æ’**: {'1-2å‘¨å†…å®Œæˆ' if action != 'æŒæœ‰' else 'æŒç»­è§‚å¯Ÿ'}

### âš ï¸ é£é™©æ§åˆ¶
- **æ­¢æŸè®¾ç½®**: è·Œç ´æ”¯æ’‘ä½ç«‹å³æ­¢æŸ
- **æ­¢ç›ˆç­–ç•¥**: è¾¾åˆ°ç›®æ ‡ä»·ä½åˆ†æ‰¹æ­¢ç›ˆ
- **ç›‘æ§è¦ç‚¹**: å¯†åˆ‡å…³æ³¨æˆäº¤é‡å’ŒæŠ€æœ¯æŒ‡æ ‡å˜åŒ–

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…äº¤æ˜“éœ€è¦é…ç½®APIå¯†é’¥*
    """

    demo_state['risk_debate_state'] = {
        'risky_history': f"""
## ğŸš€ æ¿€è¿›åˆ†æå¸ˆé£é™©è¯„ä¼°

ä»æ¿€è¿›æŠ•èµ„è§’åº¦åˆ†æ{stock_symbol}ï¼š

### ğŸ’ª é£é™©æ‰¿å—èƒ½åŠ›
- **é«˜æ”¶ç›Šæœºä¼š**: å½“å‰å¸‚åœºæä¾›äº†éš¾å¾—çš„æŠ•èµ„æœºä¼š
- **é£é™©å¯æ§**: è™½ç„¶å­˜åœ¨æ³¢åŠ¨ï¼Œä½†é•¿æœŸè¶‹åŠ¿å‘å¥½
- **æ—¶æœºæŠŠæ¡**: ç°åœ¨æ˜¯ç§¯æå¸ƒå±€çš„æœ€ä½³æ—¶æœº

### ğŸ¯ æ¿€è¿›ç­–ç•¥
- **åŠ å¤§ä»“ä½**: å»ºè®®å°†ä»“ä½æå‡è‡³60-80%
- **æ æ†ä½¿ç”¨**: å¯é€‚åº¦ä½¿ç”¨æ æ†æ”¾å¤§æ”¶ç›Š
- **å¿«é€Ÿè¡ŒåŠ¨**: æœºä¼šç¨çºµå³é€ï¼Œéœ€è¦æœæ–­å†³ç­–

**é£é™©è¯„çº§**: ä¸­ç­‰é£é™©ï¼Œé«˜æ”¶ç›Šæ½œåŠ›

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®*
        """.strip(),

        'safe_history': f"""
## ğŸ›¡ï¸ ä¿å®ˆåˆ†æå¸ˆé£é™©è¯„ä¼°

ä»é£é™©æ§åˆ¶è§’åº¦åˆ†æ{stock_symbol}ï¼š

### âš ï¸ é£é™©è¯†åˆ«
- **å¸‚åœºæ³¢åŠ¨**: å½“å‰å¸‚åœºä¸ç¡®å®šé«˜
- **ä¼°å€¼é£é™©**: éƒ¨åˆ†è‚¡ç¥¨ä¼°å€¼å·²ç»åé«˜
- **æµåŠ¨æ€§é£é™©**: éœ€è¦å…³æ³¨å¸‚åœºæµåŠ¨æ€§å˜åŒ–

### ğŸ”’ ä¿å®ˆç­–ç•¥
- **æ§åˆ¶ä»“ä½**: å»ºè®®ä»“ä½ä¸è¶…è¿‡30%
- **åˆ†æ•£æŠ•èµ„**: é¿å…è¿‡åº¦é›†ä¸­äºå•ä¸€æ ‡çš„
- **å®‰å…¨è¾¹é™…**: ç¡®ä¿æœ‰è¶³å¤Ÿçš„å®‰å…¨è¾¹é™…

**é£é™©è¯„çº§**: ä¸­é«˜é£é™©ï¼Œéœ€è¦è°¨æ…æ“ä½œ

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®*
        """.strip(),

        'neutral_history': f"""
## âš–ï¸ ä¸­æ€§åˆ†æå¸ˆé£é™©è¯„ä¼°

ä»å¹³è¡¡è§’åº¦åˆ†æ{stock_symbol}ï¼š

### ğŸ“Š å®¢è§‚è¯„ä¼°
- **æœºä¼šä¸é£é™©å¹¶å­˜**: å½“å‰å¸‚åœºæ—¢æœ‰æœºä¼šä¹Ÿæœ‰é£é™©
- **é€‚åº¦å‚ä¸**: å»ºè®®é‡‡å–é€‚åº¦å‚ä¸çš„ç­–ç•¥
- **çµæ´»è°ƒæ•´**: æ ¹æ®å¸‚åœºå˜åŒ–åŠæ—¶è°ƒæ•´ç­–ç•¥

### âš–ï¸ å¹³è¡¡ç­–ç•¥
- **ä¸­ç­‰ä»“ä½**: å»ºè®®ä»“ä½æ§åˆ¶åœ¨40-50%
- **åŠ¨æ€è°ƒæ•´**: æ ¹æ®å¸‚åœºæƒ…å†µåŠ¨æ€è°ƒæ•´ä»“ä½
- **é£é™©ç›‘æ§**: æŒç»­ç›‘æ§é£é™©æŒ‡æ ‡å˜åŒ–

**é£é™©è¯„çº§**: ä¸­ç­‰é£é™©ï¼Œå¹³è¡¡æ”¶ç›Š

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®*
        """.strip(),

        'judge_decision': f"""
## ğŸ¯ æŠ•èµ„ç»„åˆç»ç†æœ€ç»ˆé£é™©å†³ç­–

ç»¼åˆä¸‰ä½é£é™©åˆ†æå¸ˆçš„æ„è§ï¼Œæœ€ç»ˆé£é™©ç®¡ç†å†³ç­–å¦‚ä¸‹ï¼š

### ğŸ“Š é£é™©ç»¼åˆè¯„ä¼°
- **æ¿€è¿›è§‚ç‚¹**: é«˜æ”¶ç›Šæœºä¼šï¼Œå»ºè®®ç§¯æå‚ä¸
- **ä¿å®ˆè§‚ç‚¹**: é£é™©è¾ƒé«˜ï¼Œå»ºè®®è°¨æ…æ“ä½œ
- **ä¸­æ€§è§‚ç‚¹**: æœºä¼šä¸é£é™©å¹¶å­˜ï¼Œé€‚åº¦å‚ä¸

### ğŸ¯ æœ€ç»ˆé£é™©å†³ç­–
åŸºäºå½“å‰å¸‚åœºç¯å¢ƒå’Œ{stock_symbol}çš„é£é™©ç‰¹å¾ï¼š

1. **é£é™©ç­‰çº§**: ä¸­ç­‰é£é™©
2. **å»ºè®®ä»“ä½**: 40%ï¼ˆå¹³è¡¡æ”¶ç›Šä¸é£é™©ï¼‰
3. **é£é™©æ§åˆ¶**: ä¸¥æ ¼æ‰§è¡Œæ­¢æŸç­–ç•¥
4. **ç›‘æ§é¢‘ç‡**: æ¯æ—¥ç›‘æ§ï¼ŒåŠæ—¶è°ƒæ•´

**å†³ç­–ç†ç”±**: åœ¨æ§åˆ¶é£é™©çš„å‰æä¸‹ï¼Œé€‚åº¦å‚ä¸å¸‚åœºæœºä¼š

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®*
        """.strip()
    }

    demo_state['final_trade_decision'] = f"""
## ğŸ¯ æœ€ç»ˆæŠ•èµ„å†³ç­–

ç»è¿‡åˆ†æå¸ˆå›¢é˜Ÿã€ç ”ç©¶å›¢é˜Ÿã€äº¤æ˜“å›¢é˜Ÿå’Œé£é™©ç®¡ç†å›¢é˜Ÿçš„å…¨é¢åˆ†æï¼Œæœ€ç»ˆæŠ•èµ„å†³ç­–å¦‚ä¸‹ï¼š

### ğŸ“Š å†³ç­–æ‘˜è¦
- **æŠ•èµ„å»ºè®®**: **{action}**
- **ç½®ä¿¡åº¦**: {confidence:.1%}
- **é£é™©è¯„çº§**: ä¸­ç­‰é£é™©
- **é¢„æœŸæ”¶ç›Š**: {'10-20%' if action == 'ä¹°å…¥' else 'è§„é¿æŸå¤±' if action == 'å–å‡º' else 'ç¨³å¥æŒæœ‰'}

### ğŸ¯ æ‰§è¡Œè®¡åˆ’
1. **æ“ä½œæ–¹å‘**: {action}
2. **ç›®æ ‡ä»“ä½**: {'40%' if action == 'ä¹°å…¥' else '20%' if action == 'å–å‡º' else 'ç»´æŒç°çŠ¶'}
3. **æ‰§è¡Œæ—¶é—´**: {'1-2å‘¨å†…åˆ†æ‰¹æ‰§è¡Œ' if action != 'æŒæœ‰' else 'æŒç»­è§‚å¯Ÿ'}
4. **é£é™©æ§åˆ¶**: ä¸¥æ ¼æ‰§è¡Œæ­¢æŸæ­¢ç›ˆç­–ç•¥

### ğŸ“ˆ é¢„æœŸç›®æ ‡
- **ç›®æ ‡ä»·ä½**: {currency_symbol}{round(random.uniform(*price_range) * 1.15, 2)}
- **æ­¢æŸä»·ä½**: {currency_symbol}{round(random.uniform(*price_range) * 0.85, 2)}
- **æŠ•èµ„æœŸé™**: {'3-6ä¸ªæœˆ' if research_depth >= 3 else '1-3ä¸ªæœˆ'}

### âš ï¸ é‡è¦æé†’
è¿™æ˜¯åŸºäºå½“å‰å¸‚åœºç¯å¢ƒå’Œ{stock_symbol}åŸºæœ¬é¢çš„ç»¼åˆåˆ¤æ–­ã€‚æŠ•èµ„æœ‰é£é™©ï¼Œè¯·æ ¹æ®ä¸ªäººé£é™©æ‰¿å—èƒ½åŠ›è°¨æ…å†³ç­–ã€‚

**å…è´£å£°æ˜**: æœ¬åˆ†æä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚

*æ³¨æ„: è¿™æ˜¯æ¼”ç¤ºæ•°æ®ï¼Œå®é™…åˆ†æéœ€è¦é…ç½®æ­£ç¡®çš„APIå¯†é’¥*
    """

    return {
        'stock_symbol': stock_symbol,
        'analysis_date': analysis_date,
        'analysts': analysts,
        'research_depth': research_depth,
        'llm_provider': llm_provider,
        'llm_model': llm_model,
        'state': demo_state,
        'decision': demo_decision,
        'success': True,
        'error': None,
        'is_demo': True,
        'demo_reason': f"APIè°ƒç”¨å¤±è´¥ï¼Œæ˜¾ç¤ºæ¼”ç¤ºæ•°æ®ã€‚é”™è¯¯ä¿¡æ¯: {error_msg}"
    }
